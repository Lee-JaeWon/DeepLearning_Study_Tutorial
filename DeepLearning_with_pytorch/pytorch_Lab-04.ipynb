{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad34db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    1/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
      "Epoch    2/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712402\n",
      "Epoch    3/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040649\n",
      "Epoch    4/20 hypothesis: tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936157\n",
      "Epoch    5/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371010\n",
      "Epoch    6/20 hypothesis: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]) Cost: 29.758249\n",
      "Epoch    7/20 hypothesis: tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]) Cost: 10.445281\n",
      "Epoch    8/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391237\n",
      "Epoch    9/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493121\n",
      "Epoch   10/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
      "Epoch   11/20 hypothesis: tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]) Cost: 1.710555\n",
      "Epoch   12/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651412\n",
      "Epoch   13/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632369\n",
      "Epoch   14/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625924\n",
      "Epoch   15/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623420\n",
      "Epoch   16/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622141\n",
      "Epoch   17/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621262\n",
      "Epoch   18/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]) Cost: 1.620501\n",
      "Epoch   19/20 hypothesis: tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]) Cost: 1.619764\n",
      "Epoch   20/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]) Cost: 1.619046\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "# Data\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "#Init\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train.matmul(W) + b # or .mm or @\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "    epoch, nb_epochs, hypothesis.squeeze().detach(),\n",
    "    cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c3e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([-20.2702, -20.0977, -22.2014, -22.2739, -15.7411]) Cost: 37030.648438\n",
      "Epoch    1/20 hypothesis: tensor([54.8801, 70.2273, 66.7974, 74.6434, 53.1542]) Cost: 11608.172852\n",
      "Epoch    2/20 hypothesis: tensor([ 96.9540, 120.7969, 116.6246, 128.9039,  91.7261]) Cost: 3639.578613\n",
      "Epoch    3/20 hypothesis: tensor([120.5097, 149.1090, 144.5210, 159.2823, 113.3211]) Cost: 1141.846069\n",
      "Epoch    4/20 hypothesis: tensor([133.6976, 164.9599, 160.1391, 176.2901, 125.4114]) Cost: 358.939850\n",
      "Epoch    5/20 hypothesis: tensor([141.0811, 173.8342, 168.8832, 185.8121, 132.1803]) Cost: 113.539940\n",
      "Epoch    6/20 hypothesis: tensor([145.2149, 178.8026, 173.7787, 191.1431, 135.9700]) Cost: 36.620201\n",
      "Epoch    7/20 hypothesis: tensor([147.5292, 181.5842, 176.5195, 194.1277, 138.0917]) Cost: 12.509958\n",
      "Epoch    8/20 hypothesis: tensor([148.8250, 183.1415, 178.0540, 195.7986, 139.2796]) Cost: 4.952663\n",
      "Epoch    9/20 hypothesis: tensor([149.5504, 184.0134, 178.9131, 196.7341, 139.9446]) Cost: 2.583749\n",
      "Epoch   10/20 hypothesis: tensor([149.9566, 184.5015, 179.3941, 197.2579, 140.3170]) Cost: 1.841201\n",
      "Epoch   11/20 hypothesis: tensor([150.1840, 184.7748, 179.6634, 197.5510, 140.5254]) Cost: 1.608399\n",
      "Epoch   12/20 hypothesis: tensor([150.3113, 184.9278, 179.8142, 197.7152, 140.6422]) Cost: 1.535396\n",
      "Epoch   13/20 hypothesis: tensor([150.3826, 185.0134, 179.8986, 197.8071, 140.7075]) Cost: 1.512442\n",
      "Epoch   14/20 hypothesis: tensor([150.4226, 185.0614, 179.9459, 197.8585, 140.7441]) Cost: 1.505226\n",
      "Epoch   15/20 hypothesis: tensor([150.4449, 185.0882, 179.9723, 197.8872, 140.7646]) Cost: 1.502907\n",
      "Epoch   16/20 hypothesis: tensor([150.4575, 185.1032, 179.9872, 197.9033, 140.7761]) Cost: 1.502131\n",
      "Epoch   17/20 hypothesis: tensor([150.4645, 185.1116, 179.9955, 197.9123, 140.7826]) Cost: 1.501850\n",
      "Epoch   18/20 hypothesis: tensor([150.4685, 185.1163, 180.0001, 197.9173, 140.7862]) Cost: 1.501715\n",
      "Epoch   19/20 hypothesis: tensor([150.4707, 185.1189, 180.0027, 197.9201, 140.7882]) Cost: 1.501623\n",
      "Epoch   20/20 hypothesis: tensor([150.4720, 185.1204, 180.0042, 197.9217, 140.7894]) Cost: 1.501550\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델 초기화\n",
    "model = MultivariateLinearRegressionModel()\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    Hypothesis = model(x_train)\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(Hypothesis, y_train)\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "    epoch, nb_epochs, Hypothesis.squeeze().detach(),\n",
    "    cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91ec9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 0.732052\n",
      "Epoch    0/20 Batch 2/3 Cost: 2.413777\n",
      "Epoch    0/20 Batch 3/3 Cost: 3.588092\n",
      "Epoch    1/20 Batch 1/3 Cost: 0.874734\n",
      "Epoch    1/20 Batch 2/3 Cost: 3.111556\n",
      "Epoch    1/20 Batch 3/3 Cost: 2.047280\n",
      "Epoch    2/20 Batch 1/3 Cost: 2.450706\n",
      "Epoch    2/20 Batch 2/3 Cost: 2.868001\n",
      "Epoch    2/20 Batch 3/3 Cost: 0.159727\n",
      "Epoch    3/20 Batch 1/3 Cost: 2.032979\n",
      "Epoch    3/20 Batch 2/3 Cost: 1.402026\n",
      "Epoch    3/20 Batch 3/3 Cost: 2.545635\n",
      "Epoch    4/20 Batch 1/3 Cost: 3.490154\n",
      "Epoch    4/20 Batch 2/3 Cost: 1.046865\n",
      "Epoch    4/20 Batch 3/3 Cost: 2.180282\n",
      "Epoch    5/20 Batch 1/3 Cost: 3.965909\n",
      "Epoch    5/20 Batch 2/3 Cost: 0.628944\n",
      "Epoch    5/20 Batch 3/3 Cost: 0.091242\n",
      "Epoch    6/20 Batch 1/3 Cost: 2.185072\n",
      "Epoch    6/20 Batch 2/3 Cost: 3.001906\n",
      "Epoch    6/20 Batch 3/3 Cost: 0.133151\n",
      "Epoch    7/20 Batch 1/3 Cost: 0.678554\n",
      "Epoch    7/20 Batch 2/3 Cost: 2.514621\n",
      "Epoch    7/20 Batch 3/3 Cost: 3.524901\n",
      "Epoch    8/20 Batch 1/3 Cost: 1.190145\n",
      "Epoch    8/20 Batch 2/3 Cost: 4.261433\n",
      "Epoch    8/20 Batch 3/3 Cost: 0.029264\n",
      "Epoch    9/20 Batch 1/3 Cost: 1.655056\n",
      "Epoch    9/20 Batch 2/3 Cost: 1.544609\n",
      "Epoch    9/20 Batch 3/3 Cost: 2.669865\n",
      "Epoch   10/20 Batch 1/3 Cost: 0.537179\n",
      "Epoch   10/20 Batch 2/3 Cost: 0.724912\n",
      "Epoch   10/20 Batch 3/3 Cost: 6.731339\n",
      "Epoch   11/20 Batch 1/3 Cost: 0.884264\n",
      "Epoch   11/20 Batch 2/3 Cost: 2.826373\n",
      "Epoch   11/20 Batch 3/3 Cost: 1.897639\n",
      "Epoch   12/20 Batch 1/3 Cost: 2.583099\n",
      "Epoch   12/20 Batch 2/3 Cost: 2.800532\n",
      "Epoch   12/20 Batch 3/3 Cost: 0.171069\n",
      "Epoch   13/20 Batch 1/3 Cost: 2.033923\n",
      "Epoch   13/20 Batch 2/3 Cost: 3.082939\n",
      "Epoch   13/20 Batch 3/3 Cost: 0.117619\n",
      "Epoch   14/20 Batch 1/3 Cost: 2.639746\n",
      "Epoch   14/20 Batch 2/3 Cost: 1.537610\n",
      "Epoch   14/20 Batch 3/3 Cost: 0.081628\n",
      "Epoch   15/20 Batch 1/3 Cost: 1.130905\n",
      "Epoch   15/20 Batch 2/3 Cost: 2.687157\n",
      "Epoch   15/20 Batch 3/3 Cost: 2.283725\n",
      "Epoch   16/20 Batch 1/3 Cost: 2.814866\n",
      "Epoch   16/20 Batch 2/3 Cost: 0.016639\n",
      "Epoch   16/20 Batch 3/3 Cost: 2.645437\n",
      "Epoch   17/20 Batch 1/3 Cost: 0.790315\n",
      "Epoch   17/20 Batch 2/3 Cost: 3.587462\n",
      "Epoch   17/20 Batch 3/3 Cost: 0.004229\n",
      "Epoch   18/20 Batch 1/3 Cost: 1.900880\n",
      "Epoch   18/20 Batch 2/3 Cost: 3.160680\n",
      "Epoch   18/20 Batch 3/3 Cost: 0.104328\n",
      "Epoch   19/20 Batch 1/3 Cost: 1.107103\n",
      "Epoch   19/20 Batch 2/3 Cost: 3.064836\n",
      "Epoch   19/20 Batch 3/3 Cost: 0.000705\n",
      "Epoch   20/20 Batch 1/3 Cost: 2.129441\n",
      "Epoch   20/20 Batch 2/3 Cost: 3.133508\n",
      "Epoch   20/20 Batch 3/3 Cost: 0.098335\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 88, 93],\n",
    "                       [89, 91, 90],\n",
    "                       [96, 98, 100],\n",
    "                       [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "            cost.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
