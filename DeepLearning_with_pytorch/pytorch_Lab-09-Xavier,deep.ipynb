{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d775a4c",
   "metadata": {},
   "source": [
    "### mnist_nn_xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af4ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16698578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f8b2aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeJaeWon\\anaconda3\\envs\\DeepLearningStudy\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='E:\\DeepLearningStudy',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='E:\\DeepLearningStudy',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e151332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 256, bias=True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True)\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df48c651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0215, -0.0894,  0.0598,  ...,  0.0200,  0.0203,  0.1212],\n",
       "        [ 0.0078,  0.1378,  0.0920,  ...,  0.0975,  0.1458, -0.0302],\n",
       "        [ 0.1270, -0.1296,  0.1049,  ...,  0.0124,  0.1173, -0.0901],\n",
       "        ...,\n",
       "        [ 0.0661, -0.1025,  0.1437,  ...,  0.0784,  0.0977, -0.0396],\n",
       "        [ 0.0430, -0.1274, -0.0134,  ..., -0.0582,  0.1201,  0.1479],\n",
       "        [-0.1433,  0.0200, -0.0568,  ...,  0.0787,  0.0428, -0.0036]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3215b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f04598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ec4f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.246781081\n",
      "Epoch: 0002 cost = 0.092835627\n",
      "Epoch: 0003 cost = 0.062099934\n",
      "Epoch: 0004 cost = 0.043158282\n",
      "Epoch: 0005 cost = 0.032552719\n",
      "Epoch: 0006 cost = 0.024990607\n",
      "Epoch: 0007 cost = 0.021460216\n",
      "Epoch: 0008 cost = 0.019880820\n",
      "Epoch: 0009 cost = 0.015151084\n",
      "Epoch: 0010 cost = 0.015341577\n",
      "Epoch: 0011 cost = 0.012235122\n",
      "Epoch: 0012 cost = 0.012357231\n",
      "Epoch: 0013 cost = 0.010972363\n",
      "Epoch: 0014 cost = 0.008886398\n",
      "Epoch: 0015 cost = 0.008259354\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644ec16a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9807999730110168\n",
      "Label:  9\n",
      "Prediction:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeJaeWon\\anaconda3\\envs\\DeepLearningStudy\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\LeeJaeWon\\anaconda3\\envs\\DeepLearningStudy\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8deb1",
   "metadata": {},
   "source": [
    "### mnist_nn_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ca6dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d7f0c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c6beb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='E:\\DeepLearningStudy',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='E:\\DeepLearningStudy',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac6a96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 512, bias=True)\n",
    "linear2 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear3 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear4 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear5 = torch.nn.Linear(512, 10, bias=True)\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2fa390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0565,  0.0423, -0.0155,  ...,  0.1012,  0.0459, -0.0191],\n",
       "        [ 0.0772,  0.0452, -0.0638,  ...,  0.0476, -0.0638,  0.0528],\n",
       "        [ 0.0311, -0.1023, -0.0701,  ...,  0.0412, -0.1004,  0.0738],\n",
       "        ...,\n",
       "        [ 0.0334,  0.0187, -0.1021,  ...,  0.0280, -0.0583, -0.1018],\n",
       "        [-0.0506, -0.0939, -0.0467,  ..., -0.0554, -0.0325,  0.0640],\n",
       "        [-0.0183, -0.0123,  0.1025,  ..., -0.0214,  0.0220, -0.0741]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81a2d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45f8c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d46d1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.285531998\n",
      "Epoch: 0002 cost = 0.090530835\n",
      "Epoch: 0003 cost = 0.058814172\n",
      "Epoch: 0004 cost = 0.039957844\n",
      "Epoch: 0005 cost = 0.031853903\n",
      "Epoch: 0006 cost = 0.025514400\n",
      "Epoch: 0007 cost = 0.020236425\n",
      "Epoch: 0008 cost = 0.019569544\n",
      "Epoch: 0009 cost = 0.014461165\n",
      "Epoch: 0010 cost = 0.014499786\n",
      "Epoch: 0011 cost = 0.014732383\n",
      "Epoch: 0012 cost = 0.011545545\n",
      "Epoch: 0013 cost = 0.012704160\n",
      "Epoch: 0014 cost = 0.010244285\n",
      "Epoch: 0015 cost = 0.008064025\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5adbaf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9767000079154968\n",
      "Label:  8\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
