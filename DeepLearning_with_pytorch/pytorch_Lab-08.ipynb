{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f071c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MultiLayer Perception\n",
    "### Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85e3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5d502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040b7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], \n",
    "                       [0, 1], \n",
    "                       [1, 0], \n",
    "                       [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71110523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "w1 = torch.Tensor(2, 2).to(device)\n",
    "b1 = torch.Tensor(2).to(device)\n",
    "w2 = torch.Tensor(2, 1).to(device)\n",
    "b2 = torch.Tensor(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "569b88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # sigmoid function\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "    # return torch.div(torch.tensor(1), torch.add(torch.tensor(1.0), torch.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a243c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    # derivative of the sigmoid function\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d970b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "100 0.3873674273490906\n",
      "200 0.3557840585708618\n",
      "300 0.3515129089355469\n",
      "400 0.3499065339565277\n",
      "500 0.34907492995262146\n",
      "600 0.3485695719718933\n",
      "700 0.3482309579849243\n",
      "800 0.34798890352249146\n",
      "900 0.34780746698379517\n",
      "1000 0.34766656160354614\n",
      "1100 0.3475539982318878\n",
      "1200 0.34746208786964417\n",
      "1300 0.3473857045173645\n",
      "1400 0.3473212420940399\n",
      "1500 0.3472661077976227\n",
      "1600 0.34721824526786804\n",
      "1700 0.3471767008304596\n",
      "1800 0.34714022278785706\n",
      "1900 0.3471076488494873\n",
      "2000 0.34707850217819214\n",
      "2100 0.3470524251461029\n",
      "2200 0.34702885150909424\n",
      "2300 0.3470073342323303\n",
      "2400 0.34698793292045593\n",
      "2500 0.3469700217247009\n",
      "2600 0.3469536602497101\n",
      "2700 0.3469385802745819\n",
      "2800 0.34692472219467163\n",
      "2900 0.3469116687774658\n",
      "3000 0.34689947962760925\n",
      "3100 0.34688833355903625\n",
      "3200 0.34687793254852295\n",
      "3300 0.346868097782135\n",
      "3400 0.3468588888645172\n",
      "3500 0.3468502163887024\n",
      "3600 0.34684211015701294\n",
      "3700 0.3468343913555145\n",
      "3800 0.34682708978652954\n",
      "3900 0.34682005643844604\n",
      "4000 0.3468136787414551\n",
      "4100 0.34680747985839844\n",
      "4200 0.34680163860321045\n",
      "4300 0.3467959463596344\n",
      "4400 0.3467905521392822\n",
      "4500 0.34678560495376587\n",
      "4600 0.3467806577682495\n",
      "4700 0.3467760980129242\n",
      "4800 0.34677159786224365\n",
      "4900 0.3467673063278198\n",
      "5000 0.3467632532119751\n",
      "5100 0.3467593789100647\n",
      "5200 0.34675559401512146\n",
      "5300 0.34675198793411255\n",
      "5400 0.3467484414577484\n",
      "5500 0.3467451333999634\n",
      "5600 0.34674203395843506\n",
      "5700 0.34673890471458435\n",
      "5800 0.34673580527305603\n",
      "5900 0.3467329144477844\n",
      "6000 0.34673023223876953\n",
      "6100 0.3467274606227875\n",
      "6200 0.34672489762306213\n",
      "6300 0.34672239422798157\n",
      "6400 0.3467200696468353\n",
      "6500 0.34671762585639954\n",
      "6600 0.34671536087989807\n",
      "6700 0.34671318531036377\n",
      "6800 0.34671103954315186\n",
      "6900 0.34670889377593994\n",
      "7000 0.3467068672180176\n",
      "7100 0.34670495986938477\n",
      "7200 0.3467029929161072\n",
      "7300 0.34670111536979675\n",
      "7400 0.34669941663742065\n",
      "7500 0.34669768810272217\n",
      "7600 0.3466959297657013\n",
      "7700 0.3466942608356476\n",
      "7800 0.3466925621032715\n",
      "7900 0.3466911315917969\n",
      "8000 0.34668952226638794\n",
      "8100 0.34668809175491333\n",
      "8200 0.3466867208480835\n",
      "8300 0.34668517112731934\n",
      "8400 0.3466838002204895\n",
      "8500 0.34668242931365967\n",
      "8600 0.346681147813797\n",
      "8700 0.3466798663139343\n",
      "8800 0.34667855501174927\n",
      "8900 0.3466774523258209\n",
      "9000 0.346676230430603\n",
      "9100 0.3466750383377075\n",
      "9200 0.3466739058494568\n",
      "9300 0.3466727137565613\n",
      "9400 0.3466717302799225\n",
      "9500 0.3466705083847046\n",
      "9600 0.34666961431503296\n",
      "9700 0.3466684818267822\n",
      "9800 0.3466675281524658\n",
      "9900 0.34666648507118225\n",
      "10000 0.346665620803833\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "for step in range(10001):\n",
    "    # forward\n",
    "    l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    # Cost_Cross Entropy\n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
    "    \n",
    "    # Back prop (chain rule)\n",
    "    # Loss derivative!\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "    \n",
    "    # Layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "    \n",
    "    # Layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
    "    \n",
    "    # Weight update\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9c9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Xor-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "096c78a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6936068534851074\n",
      "100 0.6889212727546692\n",
      "200 0.6634229421615601\n",
      "300 0.5668157339096069\n",
      "400 0.2764393091201782\n",
      "500 0.08859294652938843\n",
      "600 0.04870596528053284\n",
      "700 0.033078014850616455\n",
      "800 0.02489047311246395\n",
      "900 0.019889725372195244\n",
      "1000 0.01653207466006279\n",
      "1100 0.01412778440862894\n",
      "1200 0.012324322015047073\n",
      "1300 0.010923009365797043\n",
      "1400 0.009803682565689087\n",
      "1500 0.008889637887477875\n",
      "1600 0.008129517547786236\n",
      "1700 0.007487570401281118\n",
      "1800 0.006938502192497253\n",
      "1900 0.006463602650910616\n",
      "2000 0.0060488334856927395\n",
      "2100 0.0056835962459445\n",
      "2200 0.005359520670026541\n",
      "2300 0.005070063751190901\n",
      "2400 0.00480996910482645\n",
      "2500 0.004575020633637905\n",
      "2600 0.004361758008599281\n",
      "2700 0.004167293664067984\n",
      "2800 0.003989296965301037\n",
      "2900 0.003825799096375704\n",
      "3000 0.0036750275176018476\n",
      "3100 0.0035356010776013136\n",
      "3200 0.0034062727354466915\n",
      "3300 0.003286037826910615\n",
      "3400 0.0031739205587655306\n",
      "3500 0.00306911114603281\n",
      "3600 0.0029709942173212767\n",
      "3700 0.0028789250645786524\n",
      "3800 0.00279231951572001\n",
      "3900 0.0027107575442641973\n",
      "4000 0.0026337443850934505\n",
      "4100 0.0025610255543142557\n",
      "4200 0.002492166357114911\n",
      "4300 0.002426867838948965\n",
      "4400 0.0023648894857615232\n",
      "4500 0.0023059772793203592\n",
      "4600 0.0022499212063848972\n",
      "4700 0.0021964821498841047\n",
      "4800 0.002145555103197694\n",
      "4900 0.0020968704484403133\n",
      "5000 0.0020503837149590254\n",
      "5100 0.002005884889513254\n",
      "5200 0.001963239861652255\n",
      "5300 0.0019223731942474842\n",
      "5400 0.0018831657944247127\n",
      "5500 0.001845497521571815\n",
      "5600 0.0018093236722052097\n",
      "5700 0.0017745394725352526\n",
      "5800 0.0017410406144335866\n",
      "5900 0.0017087964806705713\n",
      "6000 0.0016777177806943655\n",
      "6100 0.0016477148747071624\n",
      "6200 0.001618802547454834\n",
      "6300 0.0015908313216641545\n",
      "6400 0.0015638609183952212\n",
      "6500 0.0015377122908830643\n",
      "6600 0.0015124744968488812\n",
      "6700 0.0014880135422572494\n",
      "6800 0.0014643740141764283\n",
      "6900 0.0014414514880627394\n",
      "7000 0.0014192159287631512\n",
      "7100 0.0013976522022858262\n",
      "7200 0.0013767755590379238\n",
      "7300 0.001356451422907412\n",
      "7400 0.0013367694336920977\n",
      "7500 0.0013175950152799487\n",
      "7600 0.001298988237977028\n",
      "7700 0.0012809187173843384\n",
      "7800 0.0012633121805265546\n",
      "7900 0.0012461683945730329\n",
      "8000 0.0012295173946768045\n",
      "8100 0.001213269541040063\n",
      "8200 0.0011974695371463895\n",
      "8300 0.0011820427607744932\n",
      "8400 0.0011670339154079556\n",
      "8500 0.001152398413978517\n",
      "8600 0.0011381210060790181\n",
      "8700 0.0011241721222177148\n",
      "8800 0.0011106112506240606\n",
      "8900 0.0010973340831696987\n",
      "9000 0.001084355404600501\n",
      "9100 0.0010716901160776615\n",
      "9200 0.001059323432855308\n",
      "9300 0.0010472553549334407\n",
      "9400 0.0010354557307437062\n",
      "9500 0.001023865188471973\n",
      "9600 0.0010125581175088882\n",
      "9700 0.001001519849523902\n",
      "9800 0.0009907202329486609\n",
      "9900 0.000980144483037293\n",
      "10000 0.0009697479545138776\n"
     ]
    }
   ],
   "source": [
    "#nn Layers\n",
    "linear1 = torch.nn.Linear(2,2, bias = True)\n",
    "linear2 = torch.nn.Linear(2,1, bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
    "\n",
    "#define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "epoch = 10000\n",
    "for step in range(epoch + 1):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    #cos/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6671ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### xor-nn-wide-deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a732da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6946343779563904\n",
      "100 0.6931463479995728\n",
      "200 0.6931443810462952\n",
      "300 0.6931424736976624\n",
      "400 0.6931405067443848\n",
      "500 0.6931384801864624\n",
      "600 0.6931363940238953\n",
      "700 0.6931343078613281\n",
      "800 0.6931320428848267\n",
      "900 0.6931296586990356\n",
      "1000 0.6931271553039551\n",
      "1100 0.693124532699585\n",
      "1200 0.6931216716766357\n",
      "1300 0.6931185126304626\n",
      "1400 0.6931151151657104\n",
      "1500 0.6931114196777344\n",
      "1600 0.6931072473526001\n",
      "1700 0.6931027173995972\n",
      "1800 0.6930976510047913\n",
      "1900 0.6930917501449585\n",
      "2000 0.6930851340293884\n",
      "2100 0.6930775046348572\n",
      "2200 0.6930686235427856\n",
      "2300 0.6930582523345947\n",
      "2400 0.6930457353591919\n",
      "2500 0.6930309534072876\n",
      "2600 0.6930128335952759\n",
      "2700 0.6929904222488403\n",
      "2800 0.6929621696472168\n",
      "2900 0.692925751209259\n",
      "3000 0.6928777098655701\n",
      "3100 0.6928122043609619\n",
      "3200 0.6927199363708496\n",
      "3300 0.6925836801528931\n",
      "3400 0.6923707723617554\n",
      "3500 0.692011833190918\n",
      "3600 0.6913390755653381\n",
      "3700 0.6898604035377502\n",
      "3800 0.6856058239936829\n",
      "3900 0.6649138927459717\n",
      "4000 0.489219069480896\n",
      "4100 0.040626104921102524\n",
      "4200 0.008934604935348034\n",
      "4300 0.004533982370048761\n",
      "4400 0.0029434645548462868\n",
      "4500 0.0021470324136316776\n",
      "4600 0.0016756949480623007\n",
      "4700 0.0013667071470990777\n",
      "4800 0.0011497305240482092\n",
      "4900 0.0009895884431898594\n",
      "5000 0.000866863236296922\n",
      "5100 0.0007700424757786095\n",
      "5200 0.0006918264552950859\n",
      "5300 0.0006273944163694978\n",
      "5400 0.0005734930746257305\n",
      "5500 0.0005277501186355948\n",
      "5600 0.0004884647787548602\n",
      "5700 0.00045438401866704226\n",
      "5800 0.00042458303505554795\n",
      "5900 0.0003982562921009958\n",
      "6000 0.0003749117022380233\n",
      "6100 0.00035404216032475233\n",
      "6200 0.00033528980566188693\n",
      "6300 0.000318311620503664\n",
      "6400 0.00030292864539660513\n",
      "6500 0.0002889023453462869\n",
      "6600 0.00027606869116425514\n",
      "6700 0.0002642934559844434\n",
      "6800 0.00025344250025227666\n",
      "6900 0.0002433965273667127\n",
      "7000 0.00023412570590153337\n",
      "7100 0.00022545114916283637\n",
      "7200 0.00021741757518611848\n",
      "7300 0.00020990573102608323\n",
      "7400 0.0002028708695434034\n",
      "7500 0.0001962682872544974\n",
      "7600 0.00019006815273314714\n",
      "7700 0.00018422577704768628\n",
      "7800 0.00017872621538117528\n",
      "7900 0.00017356946773361415\n",
      "8000 0.00016865121142473072\n",
      "8100 0.00016401614993810654\n",
      "8200 0.00015957484720274806\n",
      "8300 0.00015541675384156406\n",
      "8400 0.00015145240467973053\n",
      "8500 0.00014768182882107794\n",
      "8600 0.00014404539251700044\n",
      "8700 0.00014060271496418864\n",
      "8800 0.000137309092679061\n",
      "8900 0.0001341793977189809\n",
      "9000 0.0001311689557041973\n",
      "9100 0.00012827773753087968\n",
      "9200 0.00012552065891213715\n",
      "9300 0.00012285300181247294\n",
      "9400 0.00012033439998049289\n",
      "9500 0.00011790520511567593\n",
      "9600 0.00011553562944754958\n",
      "9700 0.00011327039101161063\n",
      "9800 0.00011106475722044706\n",
      "9900 0.00010900816414505243\n",
      "10000 0.00010696647223085165\n"
     ]
    }
   ],
   "source": [
    "#nn Layers\n",
    "linear1 = torch.nn.Linear(2,10, bias = True)\n",
    "linear2 = torch.nn.Linear(10,10, bias = True)\n",
    "linear3 = torch.nn.Linear(10,10, bias = True)\n",
    "linear4 = torch.nn.Linear(10,1, bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)\n",
    "\n",
    "#define cost/loss & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "epoch = 10000\n",
    "for step in range(epoch + 1):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    #cos/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
